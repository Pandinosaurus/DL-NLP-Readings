# Offense and Denfense

- [2016 CVPR] **DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks**, [[paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.pdf), [[bibtex]](/Bibtex/DeepFool%20-%20a%20simple%20and%20accurate%20method%20to%20fool%20deep%20neural%20networks.bib), sources: [[LTS4/DeepFool]](https://github.com/lts4/deepfool).
- [2017 ICLR] **Delving into Transferable Adversarial Examples and Black-Box Attacks**, [[paper]](https://openreview.net/pdf?id=Sys6GJqxl), [[bibtex]](/Bibtex/Delving%20into%20Transferable%20Adversarial%20Examples%20and%20Black-Box%20Attacks.bib), sources: [[sunblaze-ucb/transferability-advdnn-pub]](https://github.com/sunblaze-ucb/transferability-advdnn-pub), [[YuguangTong/transferability-advdnn-pub]](https://github.com/YuguangTong/transferability-advdnn-pub).
- [2017 ICML] **Detecting Adversarial Samples from Artifacts**, [[paper]](https://arxiv.org/pdf/1703.00410.pdf), [[bibtex]](/Bibtex/Detecting%20Adversarial%20Samples%20from%20Artifacts.bib), sources: [[rfeinman/detecting-adversarial-samples]](https://github.com/rfeinman/detecting-adversarial-samples).
- [2018 ICLR] **Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality**, [[paper]](https://openreview.net/pdf?id=B1gJ1L2aW), [[bibtex]](/Bibtex/Characterizing%20Adversarial%20Subspaces%20Using%20Local%20Intrinsic%20Dimensionality.bib), sources: [[xingjunm/lid_adversarial_subspace_detection]](https://github.com/xingjunm/lid_adversarial_subspace_detection).
- [2018 AAAI] **EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples**, [[paper]](https://arxiv.org/pdf/1709.04114.pdf), [[bibtex]](/Bibtex/Elastic-Net%20Attacks%20to%20Deep%20Neural%20Networks%20via%20Adversarial%20Examples.bib), sources: [[IBM/EAD-Attack]](https://github.com/IBM/EAD-Attack), [[ysharma1126/EAD_Attack]](https://github.com/ysharma1126/EAD_Attack).
- [2018 ICLR] **Attacking Binarized Neural Networks**, [[paper]](https://openreview.net/pdf?id=HkTEFfZRb), [[bibtex]](/Bibtex/Attacking%20Binarized%20Neural%20Networks.bib), sources: [[AngusG/cleverhans-attacking-bnns]](https://github.com/AngusG/cleverhans-attacking-bnns).
- [2018 ICLR] **Towards Deep Learning Models Resistant to Adversarial Attacks**, [[paper]](https://openreview.net/pdf?id=rJzIBfZAb), [[bibtex]](/Bibtex/Towards%20Deep%20Learning%20Models%20Resistant%20to%20Adversarial%20Attacks.bib).
- [2018 ICLR] **Defense-GAN: Protecting Classifier Against Adversarial Attacks Using Generative Models**, [[paper]](https://openreview.net/pdf?id=BkJ3ibb0-), [[bibtex]](/Bibtex/Defense-GAN%20-%20Protecting%20Classifier%20Against%20Adversarial%20Attacks%20Using%20Generative%20Models.bib), sources: [[kabkabm/defensegan]](https://github.com/kabkabm/defensegan).
- [2018 SPW] **Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers**, [[paper]](https://arxiv.org/pdf/1801.04354.pdf), [[bibtex]](/Bibtex/Black-box%20Generation%20of%20Adversarial%20Text%20Sequences%20to%20Evade%20Deep%20Learning%20Classifiers.bib), sources: [[QData/deepWordBug]](https://github.com/QData/deepWordBug).
- [2018 EMNLP] **Generating Natural Language Adversarial Examples**, [[paper]](http://aclweb.org/anthology/D18-1316), [[bibtex]](/Bibtex/Generating%20Natural%20Language%20Adversarial%20Examples.bib), sources: [[nesl/nlp_adversarial_examples]](https://github.com/nesl/nlp_adversarial_examples).
- [2018 ACL] **HotFlip: White-Box Adversarial Examples for Text Classification**, [[paper]](http://aclweb.org/anthology/P18-2006), [[poster]](http://anthology.aclweb.org/attachments/P/P18/P18-2006.Poster.pdf), [[bibtex]](/Bibtex/HotFlip%20-%20White-Box%20Adversarial%20Examples%20for%20Text%20Classification.bib), sources: [[alicia-tsai/adversarial-sentiment-classification]](https://github.com/alicia-tsai/adversarial-sentiment-classification).
- [2018 ArXiv] **Adversarial Examples for Natural Language Classification Problems**, [[paper]](https://openreview.net/pdf?id=r1QZ3zbAZ), [[bibtex]](/Bibtex/Adversarial%20Examples%20for%20Natural%20Language%20Classification%20Problems.bib).
- [2019 ICML] **NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks**, [[paper]](http://proceedings.mlr.press/v97/li19g/li19g.pdf), [[bibtex]](https://scholar.googleusercontent.com/scholar.bib?q=info:Mn5eIUtvug8J:scholar.google.com/&output=citation&scisdr=CgU1_ws_EMa_0lNkOME:AAGBfm0AAAAAXqZhIMGtGF2GTcWbMJ4-2l08jTi82M8d&scisig=AAGBfm0AAAAAXqZhIA9E4Sx1e4PE3CFfc_-l-npYV4MT&scisf=4&ct=citation&cd=-1&hl=en), sources: [[Cold-Winter/Nattack]](https://github.com/Cold-Winter/Nattack).
- [2019 ICLR] **Improving the Generalization of Adversarial Training with Domain Adaptation**, [[paper]](https://openreview.net/pdf?id=SyfIfnC5Ym), [[bibtex]](/Bibtex/Improving%20the%20Generalization%20of%20Adversarial%20Training%20with%20Domain%20Adaptation.bib), sources: [[JHL-HUST/ATDA]](https://github.com/JHL-HUST/ATDA).
- [2019 NDSS] **TextBugger: Generating Adversarial Text Against Real-world Applications**, [[paper]](https://arxiv.org/pdf/1812.05271.pdf), [[bibtex]](/Bibtex/TextBugger%20-%20Generating%20Adversarial%20Text%20Against%20Real-world%20Applications.bib).
- [2019 ACL] **Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency**, [[paper]](https://www.aclweb.org/anthology/P19-1103.pdf), [[bibtex]](/Bibtex/Generating%20Natural%20Language%20Adversarial%20Examples%20through%20Probability%20Weighted%20Word%20Saliency.bib), sources: [[JHL-HUST/PWWS]](https://github.com/JHL-HUST/PWWS).
- [2020 AAAI] **Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment**, [[paper]](https://arxiv.org/pdf/1907.11932.pdf), [[bibtex]](/Bibtex/Is%20BERT%20Really%20Robust%20A%20Strong%20Baseline%20for%20Natural%20Language%20Attack%20on%20Text%20Classification%20and%20Entailment.bib), sources: [[jind11/TextFooler]](https://github.com/jind11/TextFooler).
- [2020 ICLR] **Query-Efficient Meta Attack to Deep Neural Networks**, [[paper]](https://openreview.net/pdf?id=Skxd6gSYDS), [[bibtex]](/Bibtex/Query-Efficient%20Meta%20Attack%20to%20Deep%20Neural%20Networks.bib), sources: [[dydjw9/MetaAttack_ICLR2020]](https://github.com/dydjw9/MetaAttack_ICLR2020/).
- [2020 ICLR] **Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions**, [[paper]](https://openreview.net/pdf?id=Skgy464Kvr), [[bibtex]](/Bibtex/Detecting%20and%20Diagnosing%20Adversarial%20Images%20with%20Class-Conditional%20Capsule%20Reconstructions.bib).
